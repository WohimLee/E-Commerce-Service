## 实现步骤
#### 1) config.py：集中配置（先写这个）

放 ES 地址、索引名、embedding 维度、批大小等，后面所有脚本都 import。

- ES_URL = "http://localhost:9200"
- INDEX = "products_sku_v1"
- EMB_DIMS = 1024
- BULK_SIZE = 500

#### 2) es_client.py：ES 连接与基础操作（第二个写）

封装：

- get_es()：返回 Elasticsearch(...)
- create_index_if_not_exists()：创建 mapping
- delete_index()（可选，方便重建）
- bulk_index()：bulk 写入

这样后面脚本都不用重复写连接/重试逻辑。

#### 3) schemas.py：Mapping JSON（第三个写）

把你要的 mapping（dense_vector + keyword filters + text fields）做成一个 Python dict 常量 PRODUCT_MAPPING。

- 便于版本迭代（v1/v2）
- 便于脚本里一键建索引

#### 4) build_dataset.py：读两份 jsonl、按 skuid join、生成 search_text（第四个写）

输出 output/merged_products.jsonl，每行是最终写 ES 的文档（先不含向量也行）。

核心要做的事：

- 读 opensearch_product_data.jsonl：以 skuid 为 key 建 dict
- 读 product_attrs.jsonl：以 skuid 为 key 建 dict（注意这里 skuid 是字符串，统一成字符串）
- join 成一个 doc
- 构造 search_text（强烈建议做成一个函数，方便调参）

search_text 拼接模板建议：
```
{group_name} {brand_name} {product_name}
属性: 季节{season} 场景{scene} 材质{material} 风格{style} 人群{people_gender} 年龄{age_range} 颜色{color} 尺码{size}
卖点: {marketing_attributes}
描述: {product_description}
```

做完这一步，你就能先用 BM25 跑通检索（即使还没向量）。

#### 5) embedder.py：embedding 生成（第五个写）

这块你可以先写“接口 + 假实现”，后续再接你选的 embedding 模型（本地 bge、或 OpenAI、或你内部服务）。

建议接口：

- class Embedder:
    - embed(texts: list[str]) -> list[list[float]]

先用 dummy（比如随机向量）把链路跑通也行，但最终要换成真实 embedding。

#### 6) index_products.py：建索引 + 批量写入（第六个写）

流程：

- create_index_if_not_exists()
- 读 output/merged_products.jsonl
- 批量取 search_text → 调 embedder.embed() → 得到 emb_text
- 拼回 doc 后 bulk 写入 ES

建议：

- bulk 里每条 action 用 _id = skuid（方便更新/去重）
- 每批 200~1000 条（看你 embedding 吞吐）

#### 7) search.py：混合检索（最后写）

实现一个 search(query: str, filters: dict, topn=50)：

- query_vector = embedder.embed([query])[0]
- 组装 ES _search body（用 retriever.rrf，包含：
    - standard：multi_match BM25
    - knn：向量 + filter
- 返回 hits（最好把 _source 限定为导购需要字段）