

# 实现步骤

---

## 🧱 阶段一：需求确认与数据准备（1–2周）

### ✅ 目标  
明确MVP（最小可行产品）范围，准备好高质量、可用于RAG的商品知识库。

### 🔧 关键动作  
- **明确MVP功能边界**  
  - 聚焦“商品智能问答”：支持基于商品描述的自然语言查询（如材质、适用场景、尺码、价格等）。  
  - 暂不支持：用户个性化推荐（需用户行为数据）、多轮复杂对话、图片输入。  

- **清洗与结构化商品数据**  
  - 合并字段：将 `product_name + marketing_attributes + product_description` 拼接为统一文本块，作为RAG的“知识单元”。  
  - 标准化属性（可选）：将颜色、尺码、季节等字段提取为结构化字段，用于后期混合检索（关键词+语义）。  
  - 去重与过滤：确保每个 `skuid` 唯一，去除空描述或无效数据。  

- **构造测试问答对（用于评估）**  
  - 人工构造50–100条典型用户问题及其标准答案（ground truth），例如：  
    - Q: “有没有适合小孩子的纯棉衬衫？” → A: WOOBABY 儿童短袖衬衫（skuid:858514）  
    - Q: “波司登那件羽绒服充绒量多少？” → A: 213g  

### 📦 产出物  
- 清洗后的商品知识库（JSON/CSV格式）  
- 测试问答评估集  
- MVP功能说明书  

### ⚠️ 注意事项  
- 保留原始字段（如 `price`, `brand_name`），便于后期做后过滤或排序。  
- 商品描述中可能含营销话术，但RAG对“噪声”有一定容忍度，不必过度清洗。  

---

## 🧠 阶段二：RAG系统搭建（2–3周）

### ✅ 目标  
搭建端到端RAG pipeline：用户提问 → 向量检索 → 大模型生成答案。

### 🔧 关键动作  
- **选择技术栈**  
  - 嵌入模型（Embedding）：`bge-large-zh-v1.5`（中文效果好，开源免费）或 `text-embedding-3-large`（若用OpenAI）  
  - 向量数据库：`Milvus`（生产级）或 `Chroma`（轻量快速验证）  
  - 大语言模型（LLM）：`Qwen-7B-Chat`（本地部署）或 `DeepSeek-Coder-1.3B`（轻量）、或调用 `Moonshot / Claude API`（快速启动）  
  - 框架：`LangChain` 或 `LlamaIndex`（简化RAG流程）  

- **构建知识库索引**  
  - 对每个商品的知识文本做分块（chunking，如512 token/块）  
  - 使用嵌入模型生成向量，并存入向量数据库  
  - 为每个向量记录元数据（`skuid`, `brand_name`, `group_name`, `price`）  

- **搭建RAG检索-生成流程**  
  ```python
  12345678910
  ```

- **本地联调测试**  
  - 在Jupyter Notebook或简单Flask API中跑通端到端流程。

### 📦 产出物  
- 可运行的RAG原型（命令行或简单Web界面）  
- 向量数据库索引文件  
- API接口文档（如 `/ask?query=...`）  

### ⚠️ 注意事项  
- 初期不必追求高并发，重点验证语义理解准确性。  
- 设置 `top-k=3~5`，避免召回噪声过大。  

---

## 📊 阶段三：评估与优化（1–2周）

### ✅ 目标  
量化RAG效果，针对性优化检索与生成质量。

### 🔧 关键动作  
- **评估指标设计**  
  - 召回率（Recall@K）：标准答案是否出现在top-K检索结果中？  
  - 准确率（Answer Accuracy）：生成答案是否事实正确？（人工评估）  
  - 相关性（Relevance）：答案是否切题？（人工打分1-5分）  

- **执行评估**  
  - 用阶段一的测试集跑RAG系统，记录指标。  
  - 分析失败案例：是检索不到？还是LLM幻觉？  

- **针对性优化**  
  - **若检索不准**：  
    - 调整分块策略（按句子/段落分，而非固定长度）  
    - 尝试HyDE（假设性文档嵌入）或Query Expansion  
    - 加入结构化字段过滤（如先按`group_name`筛“连衣裙”）  
  - **若生成不准/幻觉**：  
    - 在Prompt中强调“仅根据提供的信息回答，不知道就说不知道”  
    - 使用更小但更可控的模型（如`Qwen-1.8B`）  
    - 后处理：提取答案中的`skuid`，反向验证是否在检索结果中  

- **A/B测试（可选）**  
  - 对比不同嵌入模型或LLM的效果。

### 📦 产出物  
- 评估报告（含指标、bad case分析）  
- 优化后的RAG pipeline  
- 最终Prompt模板  

---

## 💬 阶段四：产品化封装（2–3周）

### ✅ 目标  
将RAG能力封装为可交互的产品，如Web ChatBot或API服务。

### 🔧 关键动作  
- **开发前端界面（MVP）**  
  - 使用 `Streamlit / Gradio` 快速构建聊天界面（适合内部演示）  
  - 或开发简易 `React/Vue` 前端 + WebSocket后端（面向用户）  

- **后端工程化**  
  - 用 `FastAPI/Flask` 封装RAG为RESTful API  
  - 增加缓存（Redis）避免重复查询  
  - 加入日志与监控（如记录用户query、响应时间）  

- **增强用户体验**  
  - 在答案后附带商品卡片（图片、价格、跳转链接）  
  - 支持“追问”（维护对话上下文，如“这款有其他颜色吗？”）  
  - 设置兜底逻辑：当置信度低时，回复“我还不太确定，建议您查看商品详情页”  

- **安全与合规**  
  - 输入过滤（防XSS、SQL注入）  
  - 限制查询频率（防滥用）  

### 📦 产出物  
- 可交互的Web ChatBot（内部或灰度上线）  
- 稳定的RAG API服务  
- 埋点与监控方案  

---

## 🚀 阶段五：上线与迭代（持续）

### ✅ 目标  
小流量上线，收集真实用户反馈，持续迭代。

### 🔧 关键动作  
- **灰度发布**  
  - 在APP/网站侧边栏或客服入口嵌入ChatBot，仅对10%用户可见。  

- **用户行为分析**  
  - 收集真实query、点击率、转化率（是否点击商品链接？）  
  - 分析高频问题、未命中问题  

- **持续优化**  
  - 每周更新知识库（新增商品自动索引）  
  - 根据bad case迭代Prompt和检索策略  
  - 引入用户反馈按钮（“这个回答有帮助吗？”）  

- **扩展功能（Phase 2）**  
  - 多轮对话管理：基于用户画像的上下文记忆  
  - 混合检索：关键词（Elasticsearch） + 语义（向量库）  
  - 内容生成：自动生成商品卖点摘要、营销文案  

---

## 🔒 阶段六：监控与运维（长期）

### ✅ 目标  
确保系统稳定、安全、可扩展。

### 🔧 关键动作  
- 性能监控：响应时间、错误率、GPU/CPU使用率  
- 数据漂移检测：新商品描述风格是否影响效果？  
- 成本控制：LLM API调用量、向量数据库存储成本  
- 安全审计：定期检查数据泄露、Prompt注入风险  

---

## ✅ 总结：关键成功要素

| 要素 | 建议 |
|------|------|
| 数据质量 | 商品描述越详细、结构化，RAG效果越好 |
| Prompt工程 | 严格约束LLM“不说谎”，是防幻觉关键 |
| 混合检索 | 未来可结合关键词+向量，提升精准度 |
| 用户反馈闭环 | 真实用户query是优化的金矿 |
| MVP思维 | 先跑通“问答”，再做“推荐”“导购”等高级功能 |